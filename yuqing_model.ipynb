{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# General libraries\n",
    "\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from random import randrange\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from timeit import default_timer as timer\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.dpi'] = 108\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dictionaries with the structure source -> array of followings\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "dictionary = defaultdict(list)\n",
    "# simple datafram to store the sources and the count of source followings\n",
    "data = pd.DataFrame([])\n",
    "\n",
    "file = open('data/train.txt', 'r')\n",
    "lines = file.readlines()\n",
    "count = 0\n",
    "for line in lines:\n",
    "    count = count + 1\n",
    "    split_string = list(map(int,line.strip().split(\"\\t\")))\n",
    "    dictionary[split_string[0]] = []\n",
    "    if (len(split_string) > 1):\n",
    "        dictionary[split_string[0]] = sorted(split_string[1:len(split_string)])\n",
    "\n",
    "    data = data.append(pd.DataFrame({'Source': split_string[0], 'Source_Followings': len(dictionary[split_string[0]]) }, index=[0]), ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def followingInCommon(node1,node2):\n",
    "    list1 = dictionary[node1]\n",
    "    list2 = dictionary[node2]\n",
    "    common_elements = set(list1).intersection(list2)\n",
    "    return len(common_elements)\n",
    "\n",
    "# Test\n",
    "followingInCommon(3849054,161276)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "real_edges = pd.read_csv(\"model_data/real_edges.csv\", sep='\\t')\n",
    "fake_edges = pd.read_csv(\"model_data/fake_edges.csv\", sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "real_edges['Common_Followings'] = real_edges.apply(lambda x: followingInCommon(x['Source'], x['Sink']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fake_edges['Common_Followings'] = fake_edges.apply(lambda x: followingInCommon(x['Source'], x['Sink']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#real_edges['Com_Followings_Ratio'] = real_edges['Common_Followings']/real_edges['Source_Followings']\n",
    "#fake_edges['Com_Followings_Ratio'] = fake_edges['Common_Followings']/fake_edges['Source_Followings']\n",
    "#real_edges['Followers_Ratio'] = real_edges['Sink_Followers']/real_edges['Source_Followers']\n",
    "#fake_edges['Followers_Ratio'] = fake_edges['Sink_Followers']/fake_edges['Source_Followers']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#real_edges.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "real_edges['Real'] = 1\n",
    "fake_edges['Real'] = -1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#real_edges.shape\n",
    "#fake_edges.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "frames = [real_edges, fake_edges]\n",
    "dataset = pd.concat(frames, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Shuffle the data set\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "#dataset.tail()\n",
    "#dataset['Com_Followings_Ratio'] = dataset['Com_Followings_Ratio'].fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset['Distance'] =dataset.apply(lambda x: x.Distance if x.Distance != math.inf else 2000, axis =1)\n",
    "\n",
    "dataset = dataset.drop(columns=['Source'])\n",
    "dataset = dataset.drop(columns=['Sink'])\n",
    "dataset.head()\n",
    "dataset.to_csv(\"model_data/data.csv\", sep='\\t', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#msk = np.random.rand(len(dataset)) < 0.8\n",
    "\n",
    "#Y = dataset['Real']\n",
    "#X = dataset.drop(columns=['Real'])\n",
    "train_df, test_df = train_test_split(dataset, test_size=0.2, random_state=1)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(train_df.drop('Real',axis=1))\n",
    "scaler.fit(test_df.drop('Real',axis=1))\n",
    "X_train =scaler.transform(train_df.drop('Real',axis=1))        # fill in\n",
    "Y_train =train_df.Real# fill in\n",
    "\n",
    "X_test = scaler.transform(test_df.drop('Real',axis=1)) # fill in\n",
    "Y_test = test_df.Real # fill in\n",
    "\n",
    "# Normalization\n",
    "#X = (X-X.min())/(X.max()-X.min())\n",
    "\n",
    "#X_train = X[msk]\n",
    "#X_test = X[~msk]\n",
    "#Y_train = Y[msk]\n",
    "#Y_test = Y[~msk]\n",
    "\n",
    "print(len(X_test))\n",
    "print(X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.scatter(X_train[Y_train==1,0], X_train[Y_train==1,1], X_train[Y_train==1,2],label=\"Real ($y=1$)\", c='r')\n",
    "# plt.scatter(X_train[Y_train==-1,0], X_train[Y_train==-1,1], X_train[Y_train==-1,2],label=\"Fake ($y=-1$)\", c='b')\n",
    "# #plt.xlabel(\"Heart weight\")\n",
    "# #plt.ylabel(\"Body weight\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# C_range = np.logspace(-2, 5, 8)\n",
    "# gamma_range = np.logspace(-6, 1, 16)\n",
    "#\n",
    "# # Visualise the grid\n",
    "# xx, yy = np.meshgrid(C_range, gamma_range)\n",
    "# plt.plot(xx, yy, 'ko')\n",
    "# plt.xscale('log')\n",
    "# plt.yscale('log')\n",
    "# plt.xlabel('$C$')\n",
    "# plt.ylabel(r'$\\gamma$')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#cv = StratifiedShuffleSplit(n_splits=30, test_size=0.1, random_state=1)\n",
    "#grid = GridSearchCV(SVC(kernel='rbf'), param_grid={'gamma': gamma_range, 'C': C_range}, cv=cv)\n",
    "#grid.fit(X_train, Y_train)\n",
    "#print(\"The best parameters are {0.best_params_} with an accuracy of {0.best_score_:.3g}\".format(grid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Libraries for developing a Neural Network\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Model arguments\n",
    "args = dict(x = X_train,\n",
    "            y = Y_train,\n",
    "            epochs=40,\n",
    "            validation_split=0.2,\n",
    "            verbose=2,\n",
    "            shuffle=True)\n",
    "\n",
    "# Layer definition\n",
    "input_layer = Input(shape=(7,))\n",
    "hidden_layer_1 = Dense(7, activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "#hidden_layer_1 = Dropout(0.3)(hidden_layer_1)\n",
    "#hidden_layer_2 = Dense(8, activation='sigmoid')(hidden_layer_1)\n",
    "hidden_layer_2 = Dense(7, activation='relu')(hidden_layer_1)\n",
    "#hidden_layer_2 = Dropout(0.3)(hidden_layer_2)\n",
    "output_layer = Dense(2, activation='softmax')(hidden_layer_2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Model set up\n",
    "model.compile(tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Execute training\n",
    "model.fit(**args)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)\n",
    "classes = predict.argmax(axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Accuracy: ' + \"{:.4f}\".format(accuracy_score(Y_test, classes)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"model_data/test_data.csv\", sep='\\t')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data['Distance'] =dataset.apply(lambda x: x.Distance if x.Distance != math.inf else 2000, axis =1)\n",
    "\n",
    "test_data['Common_Followings'] = test_data.apply(lambda x: followingInCommon(x['Source'], x['Sink']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data['Com_Followings_Ratio'] = test_data['Common_Followings']/test_data['Source_Followings']\n",
    "test_data['Followers_Ratio'] = test_data['Sink_Followers']/test_data['Source_Followers']\n",
    "test_data['Com_Followings_Ratio'] = test_data['Com_Followings_Ratio'].fillna(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_data.tail()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Normalization\n",
    "test_data = (test_data-test_data.min())/(test_data.max()-test_data.min())\n",
    "test_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_test = model.predict(test_data)\n",
    "classes = predict_test.argmax(axis=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predict_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame([])\n",
    "i = 0\n",
    "for row in predict_test:\n",
    "    i += 1\n",
    "    prediction = prediction.append(pd.DataFrame({'Id': i, 'Predicted': row[1]},\n",
    "                                                index=[0]), ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "prediction.to_csv(\"predictions/prediction_2020-09-10.csv\", sep=',', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}