{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from random import randrange\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Libraries for developing a Neural Network\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical \n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../data_models/dataset4.csv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the data set\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "# Filling NaN values with zeros. Not sure if it is correct.\n",
    "dataset['Com_Followings_Ratio'] = dataset['Com_Followings_Ratio'].fillna(0)\n",
    "dataset = dataset.replace([np.inf],1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source                     False\n",
       "Sink                       False\n",
       "Source_Followings          False\n",
       "Source_Followers           False\n",
       "Sink_Followers             False\n",
       "Distance                   False\n",
       "Real                       False\n",
       "Common_Followings          False\n",
       "Com_Followings_Ratio       False\n",
       "Followers_Ratio            False\n",
       "Indirect_Followings        False\n",
       "Inv_Indirect_Followings    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Source                     False\n",
       "Sink                       False\n",
       "Source_Followings          False\n",
       "Source_Followers           False\n",
       "Sink_Followers             False\n",
       "Distance                   False\n",
       "Real                       False\n",
       "Common_Followings          False\n",
       "Com_Followings_Ratio       False\n",
       "Followers_Ratio            False\n",
       "Indirect_Followings        False\n",
       "Inv_Indirect_Followings    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.isin([np.inf]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(dataset)) < 0.8\n",
    "\n",
    "Y = dataset['Real']\n",
    "X = dataset.drop(columns=['Real','Sink','Source'])\n",
    "\n",
    "# Normalization\n",
    "X = (X-X.min())/(X.max()-X.min())\n",
    "\n",
    "X_train = X[msk]\n",
    "X_test = X[~msk]\n",
    "Y_train = Y[msk]\n",
    "Y_test = Y[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_function(roc_auc_score, (y_true, y_pred), tf.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_149\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_76 (InputLayer)        [(None, 9)]               0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 50)                500       \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 20)                1020      \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,541\n",
      "Trainable params: 1,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model arguments\n",
    "args = dict(x = X_train,\n",
    "            y = Y_train,\n",
    "            epochs=16,\n",
    "            validation_split=0.2,\n",
    "            verbose=2,\n",
    "            shuffle=True)\n",
    "\n",
    "# Layer definition\n",
    "input_layer = Input(shape=(9,))\n",
    "hidden_layer_1 = Dense(50, activation='relu',activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "\n",
    "#hidden_layer_1 = Dropout(0.3)(hidden_layer_1)\n",
    "#hidden_layer_2 = Dense(8, activation='sigmoid')(hidden_layer_1)\n",
    "hidden_layer_2 = Dense(20, activation='relu')(hidden_layer_1)\n",
    "#hidden_layer_2 = Dropout(0.3)(hidden_layer_2)\n",
    "output_layer = Dense(1, activation='sigmoid')(hidden_layer_2)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Model set up\n",
    "model.compile(tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy', auroc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "161/161 - 1s - loss: 0.6720 - accuracy: 0.6185 - val_loss: 0.6560 - val_accuracy: 0.6278\n",
      "Epoch 2/16\n",
      "161/161 - 0s - loss: 0.6339 - accuracy: 0.6405 - val_loss: 0.6295 - val_accuracy: 0.6286\n",
      "Epoch 3/16\n",
      "161/161 - 0s - loss: 0.6110 - accuracy: 0.6522 - val_loss: 0.6180 - val_accuracy: 0.6527\n",
      "Epoch 4/16\n",
      "161/161 - 0s - loss: 0.5968 - accuracy: 0.6801 - val_loss: 0.6094 - val_accuracy: 0.6294\n",
      "Epoch 5/16\n",
      "161/161 - 0s - loss: 0.5838 - accuracy: 0.6807 - val_loss: 0.5944 - val_accuracy: 0.6566\n",
      "Epoch 6/16\n",
      "161/161 - 0s - loss: 0.5677 - accuracy: 0.7184 - val_loss: 0.5879 - val_accuracy: 0.8190\n",
      "Epoch 7/16\n",
      "161/161 - 0s - loss: 0.5527 - accuracy: 0.7328 - val_loss: 0.5651 - val_accuracy: 0.7125\n",
      "Epoch 8/16\n",
      "161/161 - 0s - loss: 0.5351 - accuracy: 0.7618 - val_loss: 0.5524 - val_accuracy: 0.8322\n",
      "Epoch 9/16\n",
      "161/161 - 0s - loss: 0.5155 - accuracy: 0.7866 - val_loss: 0.5258 - val_accuracy: 0.7420\n",
      "Epoch 10/16\n",
      "161/161 - 0s - loss: 0.4919 - accuracy: 0.8088 - val_loss: 0.5021 - val_accuracy: 0.8368\n",
      "Epoch 11/16\n",
      "161/161 - 0s - loss: 0.4673 - accuracy: 0.8412 - val_loss: 0.4773 - val_accuracy: 0.8190\n",
      "Epoch 12/16\n",
      "161/161 - 0s - loss: 0.4421 - accuracy: 0.8572 - val_loss: 0.4497 - val_accuracy: 0.8462\n",
      "Epoch 13/16\n",
      "161/161 - 0s - loss: 0.4120 - accuracy: 0.8667 - val_loss: 0.4218 - val_accuracy: 0.8500\n",
      "Epoch 14/16\n",
      "161/161 - 0s - loss: 0.3827 - accuracy: 0.8789 - val_loss: 0.4021 - val_accuracy: 0.8493\n",
      "Epoch 15/16\n",
      "161/161 - 0s - loss: 0.3543 - accuracy: 0.8836 - val_loss: 0.3780 - val_accuracy: 0.8834\n",
      "Epoch 16/16\n",
      "161/161 - 0s - loss: 0.3261 - accuracy: 0.8914 - val_loss: 0.3654 - val_accuracy: 0.8897\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1452cbd60>"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute training\n",
    "model.fit(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.36083418]\n",
      " [0.44239467]\n",
      " [0.3001486 ]\n",
      " ...\n",
      " [0.68271655]\n",
      " [0.3162176 ]\n",
      " [0.40478402]]\n"
     ]
    }
   ],
   "source": [
    "# Prediction for test\n",
    "predict = model.predict(X_test)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "classes = predict\n",
    "#classes = predict.argmax(-1)\n",
    "classes[classes <= 0.5] = 0\n",
    "classes[classes > 0.5] = 1\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9054\n",
      "AUC: 0.9043\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + \"{:.4f}\".format(accuracy_score(Y_test, classes)))\n",
    "print('AUC: ' + \"{:.4f}\".format(roc_auc_score(Y_test, classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0   0.950525  0.851007  0.898017       745\n",
      "           1   0.870175  0.957529  0.911765       777\n",
      "\n",
      "    accuracy                       0.905388      1522\n",
      "   macro avg   0.910350  0.904268  0.904891      1522\n",
      "weighted avg   0.909505  0.905388  0.905035      1522\n",
      "\n",
      "[[634 111]\n",
      " [ 33 744]]\n",
      "0.9053876478318003\n"
     ]
    }
   ],
   "source": [
    "# accuracy \n",
    "print (classification_report(Y_test, predict,digits = 6))\n",
    "print (confusion_matrix(Y_test, predict))\n",
    "print (accuracy_score(Y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading test data\n",
    "test_data = pd.read_csv(\"../data_generated/test_data.csv\", sep='\\t')\n",
    "test_data['Com_Followings_Ratio'] = test_data['Com_Followings_Ratio'].fillna(0)\n",
    "test_data = test_data.replace([np.inf],1000)\n",
    "# Normalization\n",
    "test_data = (test_data-test_data.min())/(test_data.max()-test_data.min())\n",
    "test_data = test_data.drop(columns=['Sink','Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1400662 ],\n",
       "       [0.19174588],\n",
       "       [0.88244605],\n",
       "       ...,\n",
       "       [0.25105727],\n",
       "       [0.24114308],\n",
       "       [0.23710889]], dtype=float32)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = model.predict(test_data)\n",
    "predict_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame([])\n",
    "i = 0\n",
    "for row in predict_test:\n",
    "    i += 1\n",
    "    prediction = prediction.append(pd.DataFrame({'Id': i, 'Predicted': row[0]},\n",
    "                                                index=[0]), ignore_index=True) \n",
    "prediction.to_csv(\"../predictions/prediction_2020-09-14-6.csv\", sep=',', index=False,float_format='%.8f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
